"""
å±‚æ¬¡åˆ‡ç‰‡ç­–ç•¥
åŸºäºæ–‡æ¡£ç»“æ„å±‚æ¬¡è¿›è¡Œåˆ‡ç‰‡
"""

def hierarchical_chunking(text, target_size=512, preserve_hierarchy=True):
    """å±‚æ¬¡åˆ‡ç‰‡ - åŸºäºæ–‡æ¡£ç»“æ„å±‚æ¬¡è¿›è¡Œåˆ‡ç‰‡"""
    chunks = []
    
    # å®šä¹‰å±‚æ¬¡æ ‡è®°
    hierarchy_markers = {
        'title1': ['# ', 'æ ‡é¢˜1ï¼š', 'ä¸€ã€', '1. '],
        'title2': ['## ', 'æ ‡é¢˜2ï¼š', 'äºŒã€', '2. '],
        'title3': ['### ', 'æ ‡é¢˜3ï¼š', 'ä¸‰ã€', '3. '],
        'paragraph': ['\n\n', '\n']
    }
    
    # åˆ†å‰²æ–‡æœ¬ä¸ºè¡Œ
    lines = text.split('\n')
    current_chunk = ""
    current_hierarchy = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # æ£€æµ‹å½“å‰è¡Œçš„å±‚æ¬¡çº§åˆ«
        line_level = None
        for level, markers in hierarchy_markers.items():
            for marker in markers:
                if line.startswith(marker):
                    line_level = level
                    break
            if line_level:
                break
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°å±‚æ¬¡æ ‡è®°ï¼Œé»˜è®¤ä¸ºæ®µè½
        if not line_level:
            line_level = 'paragraph'
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦å¼€å§‹æ–°çš„åˆ‡ç‰‡
        should_start_new_chunk = False
        
        # 1. å¦‚æœé‡åˆ°æ›´é«˜çº§åˆ«çš„æ ‡é¢˜ï¼Œå¼€å§‹æ–°åˆ‡ç‰‡
        if preserve_hierarchy and line_level in ['title1', 'title2']:
            should_start_new_chunk = True
        
        # 2. å¦‚æœå½“å‰åˆ‡ç‰‡é•¿åº¦è¶…è¿‡ç›®æ ‡å¤§å°
        if len(current_chunk) + len(line) > target_size and current_chunk.strip():
            should_start_new_chunk = True
        
        # 3. å¦‚æœé‡åˆ°æ®µè½åˆ†éš”ç¬¦ä¸”å½“å‰åˆ‡ç‰‡å·²ç»è¶³å¤Ÿé•¿
        if line_level == 'paragraph' and len(current_chunk) > target_size * 0.8:
            should_start_new_chunk = True
        
        # å¼€å§‹æ–°åˆ‡ç‰‡
        if should_start_new_chunk and current_chunk.strip():
            chunks.append(current_chunk.strip())
            current_chunk = ""
            current_hierarchy = []
        
        # æ·»åŠ å½“å‰è¡Œåˆ°åˆ‡ç‰‡
        if current_chunk:
            current_chunk += "\n" + line
        else:
            current_chunk = line
        
        # æ›´æ–°å±‚æ¬¡ä¿¡æ¯
        if line_level != 'paragraph':
            current_hierarchy.append(line_level)
    
    # å¤„ç†æœ€åä¸€ä¸ªåˆ‡ç‰‡
    # æ£€æŸ¥æœ€åä¸€ä¸ªåˆ‡ç‰‡æ˜¯å¦æœ‰å†…å®¹(å»é™¤ç©ºç™½å­—ç¬¦å),å¦‚æœæœ‰åˆ™æ·»åŠ åˆ°chunksåˆ—è¡¨ä¸­
    if current_chunk.strip():
        chunks.append(current_chunk.strip())
    
    return chunks

def print_chunk_analysis(chunks, method_name):
    """æ‰“å°åˆ‡ç‰‡åˆ†æç»“æœ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ {method_name}")
    print(f"{'='*60}")
    
    if not chunks:
        print("âŒ æœªç”Ÿæˆä»»ä½•åˆ‡ç‰‡")
        return
    
    # è®¡ç®—æ‰€æœ‰åˆ‡ç‰‡çš„æ€»å­—ç¬¦é•¿åº¦
    total_length = sum(len(chunk) for chunk in chunks)
    # è®¡ç®—åˆ‡ç‰‡çš„å¹³å‡å­—ç¬¦é•¿åº¦
    avg_length = total_length / len(chunks)
    # è·å–æœ€çŸ­åˆ‡ç‰‡çš„å­—ç¬¦é•¿åº¦
    min_length = min(len(chunk) for chunk in chunks)
    # è·å–æœ€é•¿åˆ‡ç‰‡çš„å­—ç¬¦é•¿åº¦
    max_length = max(len(chunk) for chunk in chunks)
    
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - åˆ‡ç‰‡æ•°é‡: {len(chunks)}")
    print(f"   - å¹³å‡é•¿åº¦: {avg_length:.1f} å­—ç¬¦")
    print(f"   - æœ€çŸ­é•¿åº¦: {min_length} å­—ç¬¦")
    print(f"   - æœ€é•¿é•¿åº¦: {max_length} å­—ç¬¦")
    print(f"   - é•¿åº¦æ–¹å·®: {max_length - min_length} å­—ç¬¦")
    
    print(f"\nğŸ“ åˆ‡ç‰‡å†…å®¹:")
    for i, chunk in enumerate(chunks, 1):
        print(f"   å— {i} ({len(chunk)} å­—ç¬¦):")
        print(f"   {chunk}")
        print()

# æµ‹è¯•æ–‡æœ¬ - åŒ…å«å±‚æ¬¡ç»“æ„
text = """
# è¿ªå£«å°¼ä¹å›­é—¨ç¥¨æŒ‡å—

## ä¸€ã€é—¨ç¥¨ç±»å‹ä»‹ç»

### 1. åŸºç¡€é—¨ç¥¨ç±»å‹
è¿ªå£«å°¼ä¹å›­æä¾›å¤šç§é—¨ç¥¨ç±»å‹ä»¥æ»¡è¶³ä¸åŒæ¸¸å®¢éœ€æ±‚ã€‚ä¸€æ—¥ç¥¨æ˜¯æœ€åŸºç¡€çš„é—¨ç¥¨ç±»å‹ï¼Œå¯åœ¨è´­ä¹°æ—¶é€‰å®šæ—¥æœŸä½¿ç”¨ï¼Œä»·æ ¼æ ¹æ®å­£èŠ‚æµ®åŠ¨ã€‚ä¸¤æ—¥ç¥¨éœ€è¦è¿ç»­ä¸¤å¤©ä½¿ç”¨ï¼Œæ€»ä»·æ¯”è´­ä¹°ä¸¤å¤©å•æ—¥ç¥¨ä¼˜æƒ çº¦9æŠ˜ã€‚ç‰¹å®šæ—¥ç¥¨åŒ…å«éƒ¨åˆ†èŠ‚åº†æ´»åŠ¨æ—¶æ®µï¼Œéœ€æ³¨æ„é—¨ç¥¨æ ‡æ³¨çš„æœ‰æ•ˆæœŸé™ã€‚

### 2. ç‰¹æ®Šé—¨ç¥¨ç±»å‹
å¹´ç¥¨é€‚åˆç»å¸¸æ¸¸ç©çš„æ¸¸å®¢ï¼Œæä¾›æ›´å¤šä¼˜æƒ å’Œç‰¹æƒã€‚VIPé—¨ç¥¨åŒ…å«å¿«é€Ÿé€šé“æœåŠ¡ï¼Œå¯å‡å°‘æ’é˜Ÿæ—¶é—´ã€‚å›¢ä½“ç¥¨é€‚ç”¨äº10äººä»¥ä¸Šå›¢é˜Ÿï¼Œäº«å—å›¢ä½“æŠ˜æ‰£ã€‚

## äºŒã€è´­ç¥¨æ¸ é“ä¸æµç¨‹

### 1. å®˜æ–¹è´­ç¥¨æ¸ é“
è´­ç¥¨æ¸ é“ä»¥å®˜æ–¹æ¸ é“ä¸ºä¸»ï¼ŒåŒ…æ‹¬ä¸Šæµ·è¿ªå£«å°¼å®˜ç½‘ã€å®˜æ–¹Appã€å¾®ä¿¡å…¬ä¼—å·åŠå°ç¨‹åºã€‚è¿™äº›æ¸ é“æä¾›æœ€å¯é çš„æœåŠ¡å’Œæœ€æ–°çš„ç¥¨åŠ¡ä¿¡æ¯ã€‚

### 2. ç¬¬ä¸‰æ–¹å¹³å°
ç¬¬ä¸‰æ–¹å¹³å°å¦‚é£çŒªã€æºç¨‹ç­‰åˆä½œä»£ç†å•†ä¹Ÿå¯è´­ç¥¨ï¼Œä½†éœ€è®¤å‡†å®˜æ–¹æˆæƒæ ‡è¯†ã€‚å»ºè®®ä¼˜å…ˆé€‰æ‹©å®˜æ–¹æ¸ é“ä»¥ç¡®ä¿è´­ç¥¨å®‰å…¨ã€‚

### 3. è¯ä»¶è¦æ±‚
æ‰€æœ‰ç”µå­ç¥¨éœ€ç»‘å®šèº«ä»½è¯ä»¶ï¼Œæ¸¯æ¾³å°å±…æ°‘å¯ç”¨é€šè¡Œè¯ï¼Œå¤–ç±æ¸¸å®¢ç”¨æŠ¤ç…§ï¼Œå„¿ç«¥ç¥¨éœ€æä¾›å‡ºç”Ÿè¯æ˜æˆ–æˆ·å£æœ¬å¤å°ä»¶ã€‚

## ä¸‰ã€å…¥å›­é¡»çŸ¥

### 1. å…¥å›­æ—¶é—´
ä¹å›­é€šå¸¸åœ¨ä¸Šåˆ8:00å¼€å›­ï¼Œæ™šä¸Š8:00é—­å›­ï¼Œå…·ä½“æ—¶é—´å¯èƒ½å› å­£èŠ‚å’Œç‰¹æ®Šæ´»åŠ¨è°ƒæ•´ã€‚å»ºè®®æå‰30åˆ†é’Ÿåˆ°è¾¾å›­åŒºã€‚

### 2. å®‰å…¨æ£€æŸ¥
å…¥å›­å‰éœ€è¦è¿›è¡Œå®‰å…¨æ£€æŸ¥ï¼Œç¦æ­¢æºå¸¦å±é™©ç‰©å“ã€ç»ç’ƒåˆ¶å“ç­‰ã€‚å»ºè®®è½»è£…ç®€è¡Œï¼Œæé«˜å…¥å›­æ•ˆç‡ã€‚

### 3. å›­åŒºæœåŠ¡
å›­åŒºå†…æä¾›å¯„å­˜æœåŠ¡ã€è½®æ¤…ç§Ÿèµã€å©´å„¿è½¦ç§Ÿèµç­‰æœåŠ¡ï¼Œå¯åœ¨æ¸¸å®¢æœåŠ¡ä¸­å¿ƒå’¨è¯¢è¯¦æƒ…ã€‚

ç”Ÿæ—¥ç¦åˆ©éœ€åœ¨å®˜æ–¹æ¸ é“ç™»è®°ï¼Œå¯è·èµ ç”Ÿæ—¥å¾½ç« å’Œç”œå“åˆ¸ã€‚åŠå¹´å†…æœ‰æ•ˆç»“å©šè¯æŒæœ‰è€…å¯è´­ä¹°ç‰¹åˆ«å¥—ç¥¨ï¼Œå«çš‡å®¶å®´ä¼šå…åŒäººé¤ã€‚å†›äººä¼˜æƒ ç°å½¹åŠé€€å½¹å†›äººå‡­è¯ä»¶äº«8æŠ˜ï¼Œéœ€è‡³å°‘æå‰3å¤©ç™»è®°å®¡æ‰¹ã€‚
"""

if __name__ == "__main__":
    print("ğŸ¯ å±‚æ¬¡åˆ‡ç‰‡ç­–ç•¥æµ‹è¯•")
    print(f"ğŸ“„ æµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
    
    # ä½¿ç”¨å±‚æ¬¡åˆ‡ç‰‡
    chunks = hierarchical_chunking(text, target_size=300, preserve_hierarchy=True)
    print_chunk_analysis(chunks, "å±‚æ¬¡åˆ‡ç‰‡") 