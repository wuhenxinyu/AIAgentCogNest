"""
æ»‘åŠ¨çª—å£åˆ‡ç‰‡ç­–ç•¥
å›ºå®šé•¿åº¦ã€æœ‰é‡å çš„æ–‡æœ¬åˆ†å‰²æ–¹æ³•
"""

def sliding_window_chunking(text, window_size=512, step_size=256):
    """æ»‘åŠ¨çª—å£åˆ‡ç‰‡"""
    chunks = []
    
    # ä½¿ç”¨step_sizeä½œä¸ºæ­¥é•¿,ä»æ–‡æœ¬å¼€å¤´éå†åˆ°ç»“å°¾
    for i in range(0, len(text), step_size):
        # ä»ä½ç½®iå¼€å§‹,æˆªå–window_sizeé•¿åº¦çš„æ–‡æœ¬ç‰‡æ®µ
        chunk = text[i:i + window_size]
        
        # å»é™¤é¦–å°¾ç©ºç™½å­—ç¬¦,å¦‚æœåˆ‡ç‰‡ä¸ä¸ºç©ºåˆ™æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
        if len(chunk.strip()) > 0:
            chunks.append(chunk.strip())
    
    # è¿”å›æ‰€æœ‰åˆ‡ç‰‡ç»“æœ
    return chunks

def print_chunk_analysis(chunks, method_name):
    """æ‰“å°åˆ‡ç‰‡åˆ†æç»“æœ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ {method_name}")
    print(f"{'='*60}")
    
    if not chunks:
        print("âŒ æœªç”Ÿæˆä»»ä½•åˆ‡ç‰‡")
        return
    
    total_length = sum(len(chunk) for chunk in chunks)
    avg_length = total_length / len(chunks)
    min_length = min(len(chunk) for chunk in chunks)
    max_length = max(len(chunk) for chunk in chunks)
    
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - åˆ‡ç‰‡æ•°é‡: {len(chunks)}")
    print(f"   - å¹³å‡é•¿åº¦: {avg_length:.1f} å­—ç¬¦")
    print(f"   - æœ€çŸ­é•¿åº¦: {min_length} å­—ç¬¦")
    print(f"   - æœ€é•¿é•¿åº¦: {max_length} å­—ç¬¦")
    print(f"   - é•¿åº¦æ–¹å·®: {max_length - min_length} å­—ç¬¦")
    
    print(f"\nğŸ“ åˆ‡ç‰‡å†…å®¹:")
    for i, chunk in enumerate(chunks, 1):
        print(f"   å— {i} ({len(chunk)} å­—ç¬¦):")
        print(f"   {chunk}")
        print()

# æµ‹è¯•æ–‡æœ¬
text = """
è¿ªå£«å°¼ä¹å›­æä¾›å¤šç§é—¨ç¥¨ç±»å‹ä»¥æ»¡è¶³ä¸åŒæ¸¸å®¢éœ€æ±‚ã€‚ä¸€æ—¥ç¥¨æ˜¯æœ€åŸºç¡€çš„é—¨ç¥¨ç±»å‹ï¼Œå¯åœ¨è´­ä¹°æ—¶é€‰å®šæ—¥æœŸä½¿ç”¨ï¼Œä»·æ ¼æ ¹æ®å­£èŠ‚æµ®åŠ¨ã€‚ä¸¤æ—¥ç¥¨éœ€è¦è¿ç»­ä¸¤å¤©ä½¿ç”¨ï¼Œæ€»ä»·æ¯”è´­ä¹°ä¸¤å¤©å•æ—¥ç¥¨ä¼˜æƒ çº¦9æŠ˜ã€‚ç‰¹å®šæ—¥ç¥¨åŒ…å«éƒ¨åˆ†èŠ‚åº†æ´»åŠ¨æ—¶æ®µï¼Œéœ€æ³¨æ„é—¨ç¥¨æ ‡æ³¨çš„æœ‰æ•ˆæœŸé™ã€‚

è´­ç¥¨æ¸ é“ä»¥å®˜æ–¹æ¸ é“ä¸ºä¸»ï¼ŒåŒ…æ‹¬ä¸Šæµ·è¿ªå£«å°¼å®˜ç½‘ã€å®˜æ–¹Appã€å¾®ä¿¡å…¬ä¼—å·åŠå°ç¨‹åºã€‚ç¬¬ä¸‰æ–¹å¹³å°å¦‚é£çŒªã€æºç¨‹ç­‰åˆä½œä»£ç†å•†ä¹Ÿå¯è´­ç¥¨ï¼Œä½†éœ€è®¤å‡†å®˜æ–¹æˆæƒæ ‡è¯†ã€‚æ‰€æœ‰ç”µå­ç¥¨éœ€ç»‘å®šèº«ä»½è¯ä»¶ï¼Œæ¸¯æ¾³å°å±…æ°‘å¯ç”¨é€šè¡Œè¯ï¼Œå¤–ç±æ¸¸å®¢ç”¨æŠ¤ç…§ï¼Œå„¿ç«¥ç¥¨éœ€æä¾›å‡ºç”Ÿè¯æ˜æˆ–æˆ·å£æœ¬å¤å°ä»¶ã€‚

ç”Ÿæ—¥ç¦åˆ©éœ€åœ¨å®˜æ–¹æ¸ é“ç™»è®°ï¼Œå¯è·èµ ç”Ÿæ—¥å¾½ç« å’Œç”œå“åˆ¸ã€‚åŠå¹´å†…æœ‰æ•ˆç»“å©šè¯æŒæœ‰è€…å¯è´­ä¹°ç‰¹åˆ«å¥—ç¥¨ï¼Œå«çš‡å®¶å®´ä¼šå…åŒäººé¤ã€‚å†›äººä¼˜æƒ ç°å½¹åŠé€€å½¹å†›äººå‡­è¯ä»¶äº«8æŠ˜ï¼Œéœ€è‡³å°‘æå‰3å¤©ç™»è®°å®¡æ‰¹ã€‚
"""

if __name__ == "__main__":
    print("ğŸ¯ æ»‘åŠ¨çª—å£åˆ‡ç‰‡ç­–ç•¥æµ‹è¯•")
    print(f"ğŸ“„ æµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
    
    # ä½¿ç”¨æ»‘åŠ¨çª—å£åˆ‡ç‰‡
    chunks = sliding_window_chunking(text, window_size=300, step_size=150)
    print_chunk_analysis(chunks, "æ»‘åŠ¨çª—å£åˆ‡ç‰‡") 