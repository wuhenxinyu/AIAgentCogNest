# 科普AI：UIAGENT的从0到落地的完整思路

## 第一部分：理解UIAGENT与智能体

### 1.1 什么是UIAGENT？
UIAGENT ———— 代替人操作图形界面帮助人干活的智能体（通常你可以直接想象一个人类角色，更具象化）。
而智能体，就是任何帮你干活儿的软件机器人都算。

### 1.2 理想UIAGENT的品质
想象你自己觉得的最理想的UIAGENT（甚至直接想象一个在你面前的一个帮你操作电脑干活儿的人所需具备的优秀品质）的形态———— 
* **无所不知**：不需要你解释很多常识或者背景信息；
* **万能**：啥都能干，只要人能通过图形界面操作的事甚至能不能兼顾结合一些其他手段干活儿？；
* **特别贴心**：不用用户说，有眼力动，能准确预测用户接下来想要的东西；
* **特别聪明**：操作图形界面比人更高效；
* **从不出错**：不进行无意义的动作；
* **特别靠谱**：一定会干出来一个确定的结果并且这个结果确实是最终结果；
* **想得比人更多**：碰到意外情况，能聪明地随机应变，并且提前就做好各种可能性的推测准备方案；
* **能非常无微不至**：能细致地不遗漏任何与用户达成目的有关的关键细节。

## 第二部分：品质所需的能力与仿生设计

### 2.1 品质对应的能力
接着，进一步把达成上述优秀品质所需的能力或前提稍微总结一下———— 
* **无所不知**：要知常识，知过往；
* **万能**：需要给这个人一双灵巧健康的手，鼠标，键盘、眼睛；
* **特别贴心**：知过往+知识储备高+特别的人格；
* **特别聪明**：多练习多训练；
* **从不出错**：多练习多训练；
* **特别靠谱**：多练习多训练，且足够聪明能和人互动得到验证；
* **想得比人更多**：知识储备高，特别聪明多练习多训练；
* **能非常无微不至**：知识储备高，特别聪明多练习多训练。

### 2.2 从人类到智能体的技术方案转化
最后转化成初步的可能的技木方案要求，这一步跨度可能有点大，我强烈建议任何人通过仿生的思路来整理：即深度挖掘现实生活中谁最擅长干这个场景的这件事，他具体怎么干的，这样的人有什么品质，培训这样的人要怎么做————来弄清楚具体要做什么来训练擅长干这件事的人类专家，然后将具体的事情，在基于对大模型原理的理解的基础上，转化成为粗略的技术方案，来构建擅长干这件事的机器人智能体。

记住，技术方案的合理性其实大多数时候取决于从一开始你对人类干这件事的总结是否足够干练足够合理，以及你对你自己的大脑在平时思考问题时的注意的多少。挖掘你自己的大脑怎么工作的，你能轻易通过仿生设计出优异的智能体———— 

* **无所不知**：用本身就非常强大的大模型其所携带的内置知识解决常识问题，用短期记忆解决短时间的上下文记忆问题，比如多轮对话记录———— 知道之前和用户在语言上如何互动过，动作执行记录———— 知道之前干过什么动作，长期记忆解决对特定用户使用场景的定制化理解，就像管家的笔记本记着主人的喜好。
* **万能**：眼睛：时刻给大模型当前显示器上的画面截图让它看；键盘：type动作；手+鼠标：单击，双击，拖拽，滑动；甚至你可以额外给他一些非图形界面操作工具，比如一些API接口，你的管家可能能变得更万能，但是，你要先测试一下大模型专家的能力上限，能否用好现在这些工具，这个非常重要，此外你可以像写给人类的工具说明书一样，附上说明书来指导一下你的管家具体解决问题的思路。
* **特别贴心**：很多时候就像男女关系中一方经常说的：“我不说你就不会去做”问题，其实是对对方缺乏指导，以及对方缺乏交往经验，那么此时解决方案就是训练对方———— 直接使用贴心的能力强的大模型或者微调大模型，更多时候只需提前把做事的原则和标准说清楚———— 用prompt像培养贴心男友一样交待他具体怎么做叫做贴心。
* **特别聪明**：依赖于大模型本身，所以根本解决方式是教它聪明人的做事方式-强化学习轨迹数据，此外大多数不够聪明还是很可能你没有给他足够的信息让他有更多的决策依据———— 觉得男友做事不机灵其实还是少交待了很多关键信息。
* **从不出错**：多练习多训练，也就是用更好更全面的数据训练更好的模型是根本的解决方案，但是我们可以这么想———— 设计一个机制，让他在一次决策失误时能及时发现并纠正———— 来缓解出错问题。
* **特别靠谱**：靠谱其实就是能够端到端交付工作结果，此时需要智能体能够判断其工作结果是否达到端到端交付结果的能力，且你作为用户明确描述过你的期望，如果没有明确描述过期望，那么考验的就是类似贴心和聪明一样的能力了，要能够不断和人沟通———— 即对多轮对话的内容理解能力以及决策能力———— 来判断人类用户是否达到满意来判断结果是否抵达满意的端到端终点。
* **想得比人更多**：知识储备高，特别聪明多练习多训练———— 除了进化模型本身外，给他更多的背景信息——比如用户的信息，环境的信息，特别的背景信息等信息———— 可以让大模型有更多决策依据，做出更多更长远和正确的决策，可以用仿生地从人类管家的思维中总结这些你需要的具体信息，此外还可以刻意在prompt里直接交待让模型多想想，典型的就是在决策前让模型多生成一些thinking内容，其作用和人类脑内自我思考类似。
* **能非常无微不至**：知识储备高，特别聪明多练习多训练———— 上面的其他方面已经从各个方面达成了这个效果。

## 第三部分：结合代码的进一步理解

### 3.1 具体实现细节
结合代码再看一下：

**1. 无所不知**
首先是作为管家，他的脑子里要记着之前和主人的对话，以及随身携带并翻阅更新关于主人信息，做事时的各种随笔的笔记本，还有就是———— 要稍微记住一下之前干过什么，以便完成比如尝试点击一次X，如果没反应，那么再点击Y———— 这样的事情。
其次，管家做事要有通盘的信息作为考量的依据，比如对UI AGENT通过app订餐厅，优秀的管家需要提前侦察这个订餐app的大概的页面情况，提前写在自己小本本的任务梗概里。

**2. 万能**
眼睛在代码里如下，其实就是图片，真正给你图片的眼睛其实就是车机上的截图器。
其他操作图形界面，向人类发问，以及结束任务的一些工具。
任何智能体最大的差异其实就是它能操作的工具的差异。类比人类，工具上擅长用枪，可以做各种战术动作的是军人，擅长操作手术刀，止血钳等的是外科手术医生。所以，你想要一个干什么活儿的智能体，先仿生比照现实中干这个事的人类角色是谁，他有什么具体的技能/工具。

**3. 特别贴心**
首先贴心的前提是要好好记住以前发生的事情的信息，以及好好感触并总结对方的喜好等信息，基于这些信息你才能更贴心。
其次，大模型默认是直男模式，你要和大模型玩儿角色扮演游戏，让它入戏为贴心男友并规训他。

**4. 特别聪明**
依赖于大模型本身，所以根本解决方式是教它聪明人的做事方式-强化学习轨迹数据，此外大多数不够聪明还是很可能你没有给他足够的信息让他有更多的决策依据———— 觉得男友做事不机灵其实还是少交待了很多关键信息。

**5. 从不出错**
我们使用ask_human工具可以让大模型在遇到任何它难以解决，必须求助人类的情况下，询问人类，来帮助他工作。管家也是需要一张嘴来和主人沟通的。此外，我们还额外给了UIAGENT一个叫等待的工具，如果看到界面加载中，那么就干等一会儿，可能有改观。

**6. 特别靠谱**
在订座这个场景，我们无需明确告知智能体何为成功订座，那是因为智能体看到预订成功的页面后，凭借它的常识，自然就可以判断是否完成了订座。
然而有时候我们需要告诉他做到什么程度就算完成了，比如帮你在捷停车付钱的智能体，我们明确了各种任务结束的标准。

**7. 想得比人更多**
关于思考，其实就是在对大模型的要求里明确让它动手前先写一下自己动手的原因，方便他也方便你审视该动作决策的科学性。
关于知识储备更多，其实就是给大模型更多信息辅助它决策———— 最常见的就是搜索一些信息，放到上下文中。———— 即所谓RAG，只不过RAG一般是无时无刻都在无视大模型的需要总是往它脑子里塞一些搜出来的东西，弄不好可能反而杂乱信息太多干扰判断。很不优雅，不仿生。
你可以认为给大模型一个搜索引擎工具，那么就可以达成类似效果———— 人类也是，只在自己需要的时候才去搜集需要的信息。当然这很考验使用搜索工具的能力，要求大模型本身聪明。

**8. 能非常无微不至**
知识储备高，特别聪明多练习多训练———— 上面的其他方面已经从各个方面达成了这个效果。

### 3.2 智能体设计思路
总之，关于如何从一个业务问题出发分析并搭建一个合适的智能体解决问题，请看langgraph官方的这个文档：https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph

深度代理(deepagents)概述：构建能够规划、使用子代理并利用文件系统完成复杂任务的代理。https://docs.langchain.com/oss/python/deepagents/overview#deep-agents-overview

## 第四部分：重新理解大模型与智能的本质

### 4.1 去专业名词化的理解
去专业名词化地理解大模型和智能体——去掉你所有至今脑内的一些名词的理解，重新以简单直接的方式0-1的实事求是地理解：

* **大模型**：非常擅长并把单词接龙做到极致的一个函数，本质甚至完全不复杂。所谓深度学习的神经网络，基本就是个线性多项式函数和非线性函数组合起来的函数，比如 y=tanh(ax1+bx2+cx3+d)，高中数学就能够完全参透。
* **prompt/提示词**：把事情完完全全齐齐整整信息不落下描述下来的一串字（有时加上图片等其他信息）。
* **Token**：简单理解成词汇表里的一个个词，但要注意，与字符并不是一对一关系。
* **推理**：这个推理不是人类的推理思维活动，但对大模型来说就是类似的活动———— 进行词语接龙活动 = 推理。
* **预训练**：用大量网上扒的文本，一个个词的蒙着，让大模型猜下一词是什么，猜对了给高分，猜错了给低分，然后用这个分数，修正大模型的猜词接龙策略。
* **微调**：别人已经训练好了的玩儿词语接龙很溜的大模型，再用你的场景的数据继续练练，以便更适应你的场景的风格，解决你的场景的问题。
* **强化学习**：微调的手段之一，让大模型尝试帮你干活儿，干好了，你给他打100分，没干好0分。通过这个来修正自己的猜词接龙策略。注意，这个方法和预训练相比，相当于 你进行一场演讲后得到100分 与 幼儿接龙说对一个词就给100分 的差异。这样能够训练大模型从更高层面思考和进行词语接龙。

### 4.2 单词接龙与智能的关系
那么有一个极致擅长单词接龙的函数和AI取代人类有啥关系？
想象你脑子里思考时也是在自言自语说话的，自言自语说话基本可以等价于在做单词接龙，而只有充分的思考才能说出合理的话，也就是才能做好单词接龙，没有思考也就做不到合理地自言自语说话。于是人类通过把训练思考能力 等价于 训练极致的说话能力 等价于 训练极致的单词接龙游戏能力来创建了一个专门玩儿极致单词接龙游戏的函数———— LLM，大语言模型。然后又把图片拆解成一块块的也等价成“单词+图像块”接龙的所谓的多模态大语言模型。
我们知道了做好极致单词接龙游戏需要极致的智力的关系了，相当于知道智力就是体现在这个极其简单的游戏之中了，那么剩下的就是如何让一个虽然极致聪明，但只会做单词接龙的玩意儿来做一些其他事情———— 换句话说，如何把人类遇到的各种各样的问题转化成单词接龙游戏，那么就可以用这个特别聪明的函数帮助人类解决问题。

### 4.3 大模型的工作机制
* **大模型如何和我聊天？**
    其实就是阅读一个剧本即prompt（包括多轮对话记录），然后在最后，我们要求它续写（接龙接下去）其中作为管家角色要说的下一句话，再通过外围的程序只截取出说的下一句话出来，就把多轮对话 等价 成单词接龙了。

* **误解：大模型能记住我之前说过什么，它能渐渐开始懂我。**
    大模型就是一个函数，知识以另一种方式被“固化”在其中。也就是说任何在大模型内部的知识都被时间冻结在某一个时间点了。
    你可以试试纯粹使用一个大模型推理时，他能回答“今天是几号”吗？

* **大模型如何使用工具？**
    其实就是我们在剧本即prompt中（包括多轮对话记录，工具信息等），和大模型交待，接下来你必须以某种格式，提及你想要使用的工具的名称以及可能需要提供的参数。然后通过外围程序，匹配这个特定格式并直接提取出里面的工具名称和参数信息来，送达到执行工具的机构，即可把让大模型能够通过自己的智能使用工具 等价 成单词接龙了。

* **MCP是啥？**
    各大大模型厂商统一约定好的上面大模型使用工具时所谓的“匹配这个特定格式”的特定格式及其执行机构。这样大家不用担心换了模型后新的模型不会或者不擅长生成某一个特定格式而出现无法调用工具的问题。

* **SKILLS呢？**
    想象你被老板临时安排了一个工作———— 修老板的车，并且老板丢给你一个工具箱，里面还有个修车说明书以及修车时使用工具的指南。这就是SKILLS———— 一撮工具+其使用说明书。这样你可以拿来修车工具和说明书你就是汽修工，拿来操作图形界面的工具和说明书你就是图形界面的电脑使用专家。

* **智能体和大模型啥关系？**
    人体和脑子的关系。脑子要配上手脚，感官，以及生命维持系统，才能成为人体。感官提供决策依据，脑子提供智力，手脚执行脑子的智力决策使其显现化影响环境。大模型做单词接龙 = 脑子输出电信号脉冲。

### 4.4 关于工作流
**工作流又是个啥？**
所谓工作流，你可以想象成软件层面的流水线。一件事可以分解成许多个步骤，每个步骤都可以单独完成一个相互独立的确定性的结果。
**但是！谨慎使用工作流来处理场景问题！**因为现实世界里的各个场景，大多数不是可以分解成 相互解耦独立 的步骤的，且这些步骤多数时候并不是一个有向无环图的序列。分解步骤这件事本身就不一定是符合现实状况的，模糊才是自然界的常态。
而且，如果你在每个环节还都用上了大模型，那么还存在一致性问题导致的效果不稳定，前后冲突（比如多个步骤独立各自用大模型生成一篇报告的各个部分，几乎可以肯定会存在大量的逻辑冲突）。
设计不好的工作流剥夺了大模型自由发挥的空间，降低了大模型真正能发挥的价值，甚至只带来更高的成本，并带来更低的可靠性和应对泛化性的能力。
所以优秀的新时代AI产品，往往是从不人工定义任何意图，步骤的，而是由大模型随时动态隐性决策的同时，采用非常多的外围支持，充分保证可以让大模型自主规划，测试和判断且保持一致性的同时，尽量控制上下文。

**智能体设计保证以下原则（与对人类团队的管理一样）————**
1. 在存在大量上下文影响的场景（如生成长报告），让同一个大脑干活儿。
2. 如果可以拆解成阶段性可验证的任务，那么让大模型一次只独立闭环完成一个任务。（比如编程智能体，就像危老师要求我们的一样，开发一个小功能，测一个小功能，通过了，保存并合并代码，然后可以丢弃记忆，使用新的记忆干一个新的小的可闭环任务。）
3. 从最最基本的ReAct（你可以理解成配套了可循环看到（所谓看到就是拼到上下文里）每一次自主决策后运行结果，自主进行下一步行动的简单基本智能体）智能体出发，如无必要不要复杂化什么多智能体。

## 第五部分：AI时代的核心变革与工作方法

### 5.1 黑盒与概率带来的影响
与以往传统软件确定性极强的非黑即白的逻辑不同，大模型和人脑子差不多，是个黑盒，且存在灰色地带。
我们都知道正确率，这个意思就是不是百分之百你能够解决好某一领域的问题。
黑盒与概率的引入是带来所有从售前沟通交流，交付标准约定，到产品设计，研发流程，测试交付等所有环节统统都要变更的所谓的AI时代的最大变革。

* **售前沟通**：你要让客户知道，你永远难以保证100%可靠，且如何衡量可靠本身都是一个非常困难的问题。但不是说不100%可靠=不可用。一个已经90%可靠甚至70%可靠的东西通过和人工结合互补，可以极大削减既有人工成本，帮助剩下的人工提效———— 汽车行业的辅助驾驶就是最典型的例子。沟通时注意建立权威性，不要无底线舔客户和无脑吹，这些都会很容易被识破或者承受巨大的研发交付压力。记住，你和客户是合作关系，从客户的利益角度出发，耐心，专业地沟通。必须具备基本的对概率，黑盒，大模型导致的影响的理解。
* **交付标准约定**：绝对要约定好一个评测集———— 你想象成高考试卷。约定好后阶段性不可变，达分即交付。试卷可切成两部分，用户验收用一份，研发用另一份。
* **产品设计**：大模型的超级智能带来了颠覆性的产品设计理念———— 产品设计需要充分理解如何用大模型重塑解决一个问题的解决方案，一般来说绝对不要只是把原有业务环节的每个环节简单用大模型替代了而已！那样会导致系统过于复杂和更不可靠，且并未充分发挥大模型的价值。并且知道如何从产品层面发挥AI的能力提升体验，效率以及容忍概率黑盒以及大模型的长耗时。
* **研发流程**：测试驱动一切！测试本身需要非常早期，科学但可以粗糙地开始构建测试集并评测。一切含有概率黑盒的东西都需要全量测试，不停测试，改变后就重测。
* **测试交付**：研发即测试，交付需约定可交付评测集。测试一定要具备概率论的知识和意识，没有专门的测试了。
* **总之**，从客户到所有人，理解概率，接受概率，拥抱概率。

### 5.2 重新思考：如何解决问题并顺利交付
重新思考——我/客户有一个问题，我该如何让AI解决好我/客户的问题并顺利研发与交付
让我们重新快速审视这个文档从最开头开始的思路。

1. **定义问题与评测集**：排除一切杂念，以人为本，纯粹地从用户角度出发，想清楚你想要什么，并且用例子来举例，不要提前代入任何技术方案思维。已经可以创建评测集了！端到端评测集！这个评测集甚至可以评测人类！从定下来你想要什么之后立刻！着手去创建！别忘了差不多了和你的客户沟通对齐评测集，让客户认同你的评测集就像高考试卷一样具备权威性和足够代表实际场景的难度，并且定一个验收合格线。
2. **仿生研究与设计**：从现实中寻找做类似的事情的人类角色，调研思考这样角色的人类是怎么完成类似任务的，其工作方法是什么，其脑内思维是什么。尝试模仿人类，模仿一个类似的软件的智能体。
3. **测试驱动迭代**：测试吧。测试驱动研发，测试驱动智能体/提示词的进化。先达标效果，再优化性能。
4. **核心角色转变**：让大模型干好活儿 = 用代码引用和控制拼接出一篇结构清晰，语义明确的文章。AI时代，最擅长研发AI功能的不再是程序员，而是表达能力强大，逻辑缜密，且对产品最终效果有深刻直观理解的人。
5. **成为“剧作家”**：让大模型干活，干好活儿，我认为最接近这个角色的人是剧作家。剧作家写剧本需要好好交待背景信息，人物介绍，性格介绍等等，而且要让拿到的演员能够清晰直接地理解到位。而对任何想要让AI干活的人来说，他要做的事和剧作家只有一个差异———— 用代码写剧本———— 而已。代入剧作家角度，审视最后送到大模型前一瞬间的完整的剧本篇章，读一读，作为人类阅读是否感到舒适清晰。哪里让你不舒服，哪里就很可能是要你改进的地方。