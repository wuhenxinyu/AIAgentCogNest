{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a02c8-b54d-49c6-a80f-36281fc1b1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from decord import VideoReader, cpu\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from modelscope import AutoModel, AutoTokenizer,TextIteratorStreamer\n",
    "import os\n",
    "from threading import Thread\n",
    "\n",
    "# 模型配置\n",
    "model_path = '/root/autodl-tmp/models/OpenGVLab/InternVL3_5-8B'\n",
    "\n",
    "# 初始化分词器和模型 - 使用自动多卡分配\n",
    "print(f\"可用GPU数量: {torch.cuda.device_count()}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "# 使用 AutoModel 类的 from_pretrained 方法从指定路径加载预训练模型\n",
    "model = AutoModel.from_pretrained(\n",
    "    model_path,\n",
    "    dtype=torch.bfloat16,\n",
    "    load_in_8bit=False,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attn=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\").eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, use_fast=False)\n",
    "# ImageNet 数据集的均值和标准差，用于图像归一化处理。在深度学习中，对图像数据进行归一化可以加速模型收敛，\n",
    "# 并提升模型的稳定性和泛化能力。这里的均值和标准差是 ImageNet 大规模图像数据集上计算得到的统计值，\n",
    "# 后续会在图像预处理流程中使用这些值对输入图像进行标准化操作。\n",
    "# IMAGENET_MEAN 中的三个值分别表示 ImageNet 数据集中图像在 RGB 三个通道上的均值\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "# IMAGENET_STD 中的三个值分别表示 ImageNet 数据集中图像在 RGB 三个通道上的标准差\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    \"\"\"\n",
    "    构建一个用于对输入图像进行预处理的转换流水线，包含图像格式转换、尺寸调整、转换为张量以及归一化等操作。\n",
    "    \n",
    "    参数:\n",
    "        input_size: 输入图像大小\n",
    "    \n",
    "    返回:\n",
    "        transform: 转换pipeline\n",
    "    \"\"\"\n",
    "    # 从全局变量中获取 ImageNet 数据集的均值和标准差，用于后续图像归一化处理\n",
    "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
    "    # 使用 torchvision.transforms.Compose 方法构建一个图像转换流水线，按顺序执行一系列图像转换操作\n",
    "    transform = T.Compose([\n",
    "        # 使用 Lambda 表达式检查图像模式，如果图像模式不是 RGB，则将其转换为 RGB 模式\n",
    "        T.Lambda(lambda img: img.convert(\"RGB\") if img.mode != \"RGB\" else img), \n",
    "        # 将图像调整为指定大小 (input_size, input_size)，使用双三次插值方法\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC), \n",
    "        # 将 PIL 图像或 NumPy 数组转换为 PyTorch 张量\n",
    "        T.ToTensor(), \n",
    "        # 使用 ImageNet 的均值和标准差对图像张量进行归一化处理，加速模型收敛并提升稳定性，每个通道分别减去均值并除以标准差\n",
    "        # 归一化处理可以将图像的像素值缩放到 [-1, 1] 范围内，这有助于模型训练的稳定性和收敛速度\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    \"\"\"\n",
    "    寻找最接近原始图像宽高比的目标比例\n",
    "    \n",
    "    参数:\n",
    "        aspect_ratio: 原始图像的宽高比\n",
    "        target_ratios: 目标比例列表\n",
    "        width: 原始图像宽度\n",
    "        height: 原始图像高度\n",
    "        image_size: 目标图像大小\n",
    "        \n",
    "    返回:\n",
    "        best_ratio: 最佳比例\n",
    "    \"\"\"\n",
    "    # 初始化最佳比例差异为正无穷大，用于后续比较时能找到更小的差异值，inf 表示正无穷大\n",
    "    # 初始化最佳比例为 (1, 1)，作为初始的默认最佳比例\n",
    "    best_ratio_diff = float(\"inf\")\n",
    "    best_ratio = (1, 1)\n",
    "    # 计算原始图像的面积，后续用于在比例差异相同时进行进一步的筛选\n",
    "    # 原始图像面积 = 宽度 * 高度\n",
    "    area = width * height\n",
    "\n",
    "    # 遍历目标比例列表，寻找最接近原始图像宽高比的目标比例\n",
    "    for ratio in target_ratios:\n",
    "        # 计算当前目标比例对应的宽高比\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        # 计算原始图像宽高比与当前目标宽高比的差异绝对值\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "\n",
    "        # 如果当前比例差异小于最佳比例差异，更新最佳比例差异和最佳比例\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        # 如果当前比例差异等于最佳比例差异，进行进一步筛选\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            # 如果原始图像面积大于目标图像面积的一半（目标图像面积由目标比例和图像尺寸计算得出），更新最佳比例\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "\n",
    "    # 返回找到的最接近原始图像宽高比的目标比例\n",
    "    return best_ratio\n",
    "\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=6, image_size=448, use_thumbnail=False):\n",
    "    \"\"\"\n",
    "    动态预处理图像，根据宽高比将图像分割成多个块\n",
    "    \n",
    "    参数:\n",
    "        image: 原始图像\n",
    "        min_num: 最小块数\n",
    "        max_num: 最大块数\n",
    "        image_size: 目标图像大小\n",
    "        use_thumbnail: 是否使用缩略图\n",
    "        \n",
    "    返回:\n",
    "        processed_images: 处理后的图像列表\n",
    "    \"\"\"\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # 计算现有图像宽高比\n",
    "    target_ratios = set((i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # 寻找最接近目标的宽高比\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # 计算目标宽度和高度\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # 调整图像大小\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = ((i % (target_width // image_size)) * image_size, (i // (target_width // image_size)) * image_size, \n",
    "               ((i % (target_width // image_size)) + 1) * image_size, ((i // (target_width // image_size)) + 1) * image_size)\n",
    "        # 分割图像\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "\n",
    "def load_image(image, input_size=448, max_num=6):\n",
    "    \"\"\"\n",
    "    加载并处理图像\n",
    "    \n",
    "    参数:\n",
    "        image: 输入图像\n",
    "        input_size: 输入大小\n",
    "        max_num: 最大块数\n",
    "        \n",
    "    返回:\n",
    "        pixel_values: 处理后的图像张量\n",
    "    \"\"\"\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    # 使用 torch.stack 方法将多个图像张量合并为一个批次张量。\n",
    "    # pixel_values 是一个包含多个图像张量的列表，每个张量代表经过预处理后的单张图像。\n",
    "    # torch.stack 会在新的维度上对这些张量进行拼接，创建一个新的批次张量。\n",
    "    # 例如，如果列表中有 N 个形状为 (C, H, W) 的图像张量，经过 stack 操作后，\n",
    "    # 输出张量的形状将变为 (N, C, H, W)，方便后续模型批量处理。\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n",
    "\n",
    "\n",
    "def get_index(bound, fps, max_frame, first_idx=0, num_segments=32):\n",
    "    \"\"\"\n",
    "    获取视频帧索引\n",
    "    \n",
    "    参数:\n",
    "        bound: 时间边界 [开始时间, 结束时间]\n",
    "        fps: 视频帧率\n",
    "        max_frame: 最大帧数\n",
    "        first_idx: 第一帧索引\n",
    "        num_segments: 分段数量\n",
    "        \n",
    "    返回:\n",
    "        frame_indices: 帧索引数组\n",
    "    \"\"\"\n",
    "    if bound:\n",
    "        start, end = bound[0], bound[1]\n",
    "    else:\n",
    "        start, end = -100000, 100000\n",
    "    start_idx = max(first_idx, round(start * fps))\n",
    "    end_idx = min(round(end * fps), max_frame)\n",
    "    seg_size = float(end_idx - start_idx) / num_segments\n",
    "    frame_indices = np.array([int(start_idx + (seg_size / 2) + np.round(seg_size * idx)) for idx in range(num_segments)])\n",
    "    return frame_indices\n",
    "\n",
    "def get_num_frames_by_duration(duration):\n",
    "    \"\"\"\n",
    "    根据视频时长计算帧数\n",
    "    \n",
    "    参数:\n",
    "        duration: 视频时长（秒）\n",
    "        \n",
    "    返回:\n",
    "        num_frames: 计算出的帧数\n",
    "    \"\"\"\n",
    "    local_num_frames = 4        \n",
    "    num_segments = int(duration // local_num_frames)\n",
    "    if num_segments == 0:\n",
    "        num_frames = local_num_frames\n",
    "    else:\n",
    "        num_frames = local_num_frames * num_segments\n",
    "    \n",
    "    num_frames = min(512, num_frames)\n",
    "    num_frames = max(128, num_frames)\n",
    "\n",
    "    return num_frames\n",
    "\n",
    "def load_video(video_path, bound=None, input_size=448, max_num=1, num_segments=32, get_frame_by_duration = False):\n",
    "    \"\"\"\n",
    "    加载并处理视频\n",
    "    \n",
    "    参数:\n",
    "        video_path: 视频路径\n",
    "        bound: 时间边界\n",
    "        input_size: 输入大小\n",
    "        max_num: 最大块数\n",
    "        num_segments: 分段数量\n",
    "        get_frame_by_duration: 是否根据时长获取帧数\n",
    "        \n",
    "    返回:\n",
    "        pixel_values: 处理后的视频帧张量\n",
    "        num_patches_list: 每帧的块数列表\n",
    "    \"\"\"\n",
    "    vr = VideoReader(video_path, ctx=cpu(0), num_threads=10) # 增加线程数加速读取\n",
    "    max_frame = len(vr) - 1\n",
    "    fps = float(vr.get_avg_fps())\n",
    "\n",
    "    pixel_values_list, num_patches_list = [], []\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    if get_frame_by_duration:\n",
    "        duration = max_frame / fps\n",
    "        num_segments = get_num_frames_by_duration(duration)\n",
    "    frame_indices = get_index(bound, fps, max_frame, first_idx=0, num_segments=num_segments)\n",
    "    for frame_index in frame_indices:\n",
    "        img = Image.fromarray(vr[frame_index].asnumpy()).convert(\"RGB\")\n",
    "        img = dynamic_preprocess(img, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "        pixel_values = [transform(tile) for tile in img]\n",
    "        pixel_values = torch.stack(pixel_values)\n",
    "        num_patches_list.append(pixel_values.shape[0])\n",
    "        pixel_values_list.append(pixel_values)\n",
    "    # 将存储每帧图像张量的列表 pixel_values_list 中的所有张量在第 0 维（批次维度）上进行拼接。\n",
    "    # 在 load_video 函数中，pixel_values_list 存储了视频中每个采样帧经过预处理和分块后的图像张量，\n",
    "    # 每个张量的形状可能为 (num_patches, C, H, W)，其中 num_patches 表示该帧图像被分割成的块数，\n",
    "    # C 是通道数，H 和 W 是图像的高度和宽度。通过 torch.cat 操作，将所有帧的图像块张量拼接成一个大的张量，\n",
    "    # 最终得到的 pixel_values 张量形状为 (total_patches, C, H, W)，方便后续模型对所有图像块进行批量处理。\n",
    "    # 处理后的视频帧批量移动到GPU，减少设备间传输次数\n",
    "    pixel_values = torch.cat(pixel_values_list).to(model.device, non_blocking=True)\n",
    "    # 处理后的视频帧批量移动到GPU，减少设备间传输次数\n",
    "    # num_patches_list = torch.tensor(num_patches_list, dtype=torch.long, device=model.device, non_blocking=True)\n",
    "    return pixel_values, num_patches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfde11e-e0b0-41d6-b302-1fd13d61ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# 评估设置\n",
    "# max_num_frames = 64\n",
    "generation_config = dict(\n",
    "    do_sample=False,  # 启用采样，使用贪婪解码\n",
    "    temperature=0.0,  # 温度参数，设置为0.0表示禁用采样\n",
    "    max_new_tokens=1024,  # 最大新生成令牌数\n",
    "    top_p=0.1,  #  nucleus sampling 概率阈值\n",
    "    num_beams=1,  # 束搜索束数\n",
    ")\n",
    "\n",
    "video_path = \"car.mp4\"\n",
    "num_segments=8  # 视频片段数，如果机器显存不够就减小当前值\n",
    "\n",
    "# torch.no_grad() 来禁用梯度计算\n",
    "with torch.no_grad():\n",
    "  # 清理GPU缓存\n",
    "  # torch.cuda.empty_cache()\n",
    "  # gc.collect()\n",
    "  # torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "  # 查看当前内存使用情况\n",
    "  # print(f\"当前GPU内存使用: {torch.cuda.memory_allocated()/1024**3:.2f} GiB\")\n",
    "  # print(f\"最大GPU内存使用: {torch.cuda.max_memory_allocated()/1024**3:.2f} GiB\")\n",
    "    \n",
    "  # 启用自动混合精度\n",
    "  # 加载视频并处理\n",
    "  pixel_values, num_patches_list = load_video(video_path, num_segments=num_segments, max_num=1, get_frame_by_duration=False)\n",
    "  pixel_values = pixel_values.to(torch.bfloat16).to(model.device)\n",
    "  video_prefix = \"\".join([f\"Frame{i+1}: <image>\\n\" for i in range(len(num_patches_list))])\n",
    "  \n",
    "  # 单轮对话：视频详细描述\n",
    "  question1 = \"Describe this video in detail.\"\n",
    "  question = video_prefix + question1\n",
    "  output1, chat_history = model.chat(tokenizer, pixel_values, question, generation_config, num_patches_list=num_patches_list, history=None, return_history=True)\n",
    "  print(output1)\n",
    "  \n",
    "  # 多轮对话：询问视频中的人数\n",
    "  question2 = \"How many people appear in the video?\"\n",
    "  output2, chat_history = model.chat(tokenizer, pixel_values, question2, generation_config, num_patches_list=num_patches_list, history=chat_history, return_history=True)\n",
    "  \n",
    "  print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e46cc5-6db7-4a02-95b4-0ce94fd6fd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  # 单轮对话：询问车辆损伤部位（中文）\n",
    "  question1 = \"车的哪个部位损伤了？\"\n",
    "  question = video_prefix + question1\n",
    "  output1, chat_history = model.chat(tokenizer, pixel_values, question, generation_config, num_patches_list=num_patches_list, history=None, return_history=True)\n",
    "  print(output1)\n",
    "  \n",
    "  # 多轮对话：询问车辆碰撞位置（中文）\n",
    "  question2 = \"车撞到哪里了？\"\n",
    "  output2, chat_history = model.chat(tokenizer, pixel_values, question2, generation_config, num_patches_list=num_patches_list, history=chat_history, return_history=True)\n",
    "  \n",
    "  print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582423a-4252-4c64-b7ab-b4c610ce6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用流传输\n",
    "# Initialize the streamer\n",
    "streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True, timeout=10)\n",
    "# Define the generation configuration\n",
    "generation_config = dict(max_new_tokens=1024, do_sample=False, streamer=streamer)\n",
    "video_path = \"car.mp4\"\n",
    "num_segments=8  # 视频片段数，如果机器显存不够就减小当前值\n",
    "with torch.no_grad():\n",
    "    # 启用自动混合精度\n",
    "    # 加载视频并处理\n",
    "    pixel_values, num_patches_list = load_video(video_path, num_segments=num_segments, max_num=1, get_frame_by_duration=False)\n",
    "    pixel_values = pixel_values.to(torch.bfloat16).to(model.device)\n",
    "    video_prefix = \"\".join([f\"Frame{i+1}: <image>\\n\" for i in range(len(num_patches_list))])\n",
    "    # 单轮对话：询问车辆损伤部位（中文）\n",
    "    question1 = \"车的哪个部位损伤了？\"\n",
    "    question = video_prefix + question1\n",
    "    # Start the model chat in a separate thread\n",
    "    thread = Thread(target=model.chat, kwargs=dict(\n",
    "        tokenizer=tokenizer, pixel_values=pixel_values, question=question,\n",
    "        history=None, return_history=False, generation_config=generation_config,\n",
    "    ))\n",
    "    thread.start()\n",
    "    \n",
    "    # Initialize an empty string to store the generated text\n",
    "    generated_text = ''\n",
    "    # Loop through the streamer to get the new text as it is generated\n",
    "    for new_text in streamer:\n",
    "        if new_text == model.conv_template.sep:\n",
    "            break\n",
    "        generated_text += new_text\n",
    "        print(new_text, end='', flush=True)  # Print each new chunk of generated text on the same line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44819900-a1c0-4341-8a0c-014b5c3c9979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
